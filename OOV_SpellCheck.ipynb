{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas\n",
    "import re\n",
    "from spacy.lang.en import English\n",
    "from spacy.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oovChecker():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\"]) # using default tokeniser with NER\n",
    "        with open('./uncased_L-4_H-512_A-8/vocab.txt') as f:\n",
    "            # if want to remove '[unusedXX]' from vocab\n",
    "            # words = [line.rstrip() for line in f if not line.startswith('[unused')]\n",
    "            words = [line.rstrip() for line in f]\n",
    "        self.vocab = Vocab(strings=words)\n",
    " \n",
    "        \n",
    "    ## query --> \"aa bb cc...\"\n",
    "    def misspellIdentify(self, query):\n",
    "        \"\"\"\n",
    "        At present, All the following criteria should be met for word to be misspelled\n",
    "        1. Should not in our vocab\n",
    "        2. should not be a Person\n",
    "        3. Should not be a number\n",
    "        \"\"\"\n",
    "        doc = self.nlp(query)\n",
    "        misspell = []\n",
    "        for token in doc:\n",
    "            if((token.text.lower() not in vocab) and \n",
    "               (token.ent_type_ != 'PERSON') and \n",
    "               (not token.like_num)):\n",
    "                \n",
    "                misspell.append(token)\n",
    "                \n",
    "        return misspell\n",
    "    \n",
    "    def candidateGenerator(self, misspellings):\n",
    "        return {\"misspell-1\":[\"candidate-1\",\"candidate-2\"]}\n",
    "    \n",
    "    def candidateRanking(self, misspellingsDict):\n",
    "        return {\"misspell-1\":\"Best_candidate\"}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tru, milion]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker = oovChecker()\n",
    "checker.misspellIdentify(\"this is my India. My name is Rajat Goel. I use tru. Net income was $9.4 million compared to the prior year of $2.7 milion. my number is 5362722.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this \n",
      "is \n",
      "my \n",
      "pakistan \n",
      ". \n",
      "My \n",
      "name \n",
      "is \n",
      "Rajat PERSON\n",
      "Goel PERSON\n",
      ". \n",
      "I \n",
      "use \n",
      "tru \n",
      ". \n",
      "Net \n",
      "income \n",
      "was \n",
      "$ MONEY\n",
      "9.4 MONEY\n",
      "million MONEY\n",
      "compared \n",
      "to \n",
      "the DATE\n",
      "prior DATE\n",
      "year DATE\n",
      "of \n",
      "$ \n",
      "2.7 MONEY\n",
      "milion \n",
      ". \n",
      "my \n",
      "number \n",
      "is \n",
      "5362722.2 CARDINAL\n",
      "[tru, milion]\n",
      "30522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\"])\n",
    "# nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "\n",
    "doc = nlp(\"this is my pakistan. My name is Rajat Goel. I use tru. Net income was $9.4 million compared to the prior year of $2.7 milion. my number is 5362722.2\")\n",
    "\n",
    "        \n",
    "from spacy.vocab import Vocab\n",
    "with open('./uncased_L-4_H-512_A-8/vocab.txt') as f:\n",
    "    # if want to remove '[unusedXX]' from vocab\n",
    "    # words = [line.rstrip() for line in f if not line.startswith('[unused')]\n",
    "    words = [line.rstrip() for line in f]\n",
    "    \n",
    "vocab = Vocab(strings=words)\n",
    "# for i in tokens:\n",
    "#     print(i.text.lower() in vocab, i.text)\n",
    "\n",
    "\n",
    "# a= [token for token in doc if (token.text.lower() not in vocab  & token.ent_type != 'PERSON') ]\n",
    "\n",
    "lst = []\n",
    "for token in doc:\n",
    "    print(token.text, token.ent_type_)\n",
    "    if((token.text.lower() not in vocab) and (token.ent_type_ != 'PERSON') and (not token.like_num)):\n",
    "#         print(token.text, token.ent_type_, token.is_digit, token.like_num)\n",
    "        lst.append(token)\n",
    "        \n",
    "print(lst)\n",
    "# print(a[0].i,a[0], a[0].ent_type)\n",
    "\n",
    "# print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "print(len(vocab))\n",
    "\"apple\" in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57852"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
