{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.vocab import Vocab\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import spacy\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oovChecker():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\"]) # using default tokeniser with NER\n",
    "        with open('./uncased_L-4_H-512_A-8/vocab.txt') as f:\n",
    "            # if want to remove '[unusedXX]' from vocab\n",
    "            # words = [line.rstrip() for line in f if not line.startswith('[unused')]\n",
    "            words = [line.rstrip() for line in f]\n",
    "        self.vocab = Vocab(strings=words)\n",
    "        self.BertTokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "        self.BertModel = AutoModelWithLMHead.from_pretrained(\"bert-base-cased\")\n",
    "        self.mask = self.BertTokenizer.mask_token\n",
    "            \n",
    "        # This is temp\n",
    "        self.query = \"this is my India. My name is Rajat Goel. I use tru. income was $9.4 million compared to the prior year of $2.7 milion. number is 62722.2\"\n",
    "\n",
    "  \n",
    "    ## query --> \"aa bb cc...\"\n",
    "    def misspellIdentify(self, query=''):\n",
    "        \"\"\"\n",
    "        At present, All the following criteria should be met for word to be misspelled\n",
    "        1. Should not in our vocab\n",
    "        2. should not be a Person\n",
    "        3. Should not be a number\n",
    "        \"\"\"\n",
    "        if query == '':\n",
    "            query = self.query\n",
    "            \n",
    "        doc = self.nlp(query)\n",
    "        misspell = []\n",
    "        for token in doc:\n",
    "            if((token.text.lower() not in self.vocab) and \n",
    "               (token.ent_type_ != 'PERSON') and \n",
    "               (not token.like_num)):\n",
    "                \n",
    "                misspell.append(token)\n",
    "        \n",
    "        print(misspell)\n",
    "        return misspell\n",
    "    \n",
    "    def candidateGenerator(self, misspellings, query=''):\n",
    "            \n",
    "        for token in misspellings:\n",
    "            if query == '':\n",
    "                updatedQuery = self.query\n",
    "            updatedQuery = updatedQuery.replace(token.text, self.mask)\n",
    "            print(updatedQuery)\n",
    "\n",
    "            model_input = self.BertTokenizer.encode(updatedQuery, return_tensors=\"pt\")\n",
    "            mask_token_index = torch.where(model_input == self.BertTokenizer.mask_token_id)[1]\n",
    "            token_logits = self.BertModel(model_input)[0]\n",
    "            mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "            top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()  \n",
    "            for candidate in top_5_tokens:\n",
    "                print(updatedQuery.replace(self.mask, self.BertTokenizer.decode([candidate])))\n",
    "                \n",
    "            print('=='*20)\n",
    "\n",
    "\n",
    "        return {\"misspell-1\":[\"candidate-1\",\"candidate-2\"]}\n",
    "    \n",
    "    def candidateRanking(self, misspellingsDict):\n",
    "        return {\"misspell-1\":\"Best_candidate\"}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tru, milion]\n",
      "misspellTokens [tru, milion]\n",
      "this is my India. My name is Rajat Goel. I use [MASK]. income was $9.4 million compared to the prior year of $2.7 milion. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use it. income was $9.4 million compared to the prior year of $2.7 milion. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use you. income was $9.4 million compared to the prior year of $2.7 milion. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use English. income was $9.4 million compared to the prior year of $2.7 milion. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use this. income was $9.4 million compared to the prior year of $2.7 milion. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use money. income was $9.4 million compared to the prior year of $2.7 milion. number is 62722.2\n",
      "========================================\n",
      "this is my India. My name is Rajat Goel. I use tru. income was $9.4 million compared to the prior year of $2.7 [MASK]. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use tru. income was $9.4 million compared to the prior year of $2.7 million. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use tru. income was $9.4 million compared to the prior year of $2.7 billion. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use tru. income was $9.4 million compared to the prior year of $2.7 Million. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use tru. income was $9.4 million compared to the prior year of $2.7 ##M. number is 62722.2\n",
      "this is my India. My name is Rajat Goel. I use tru. income was $9.4 million compared to the prior year of $2.7 trillion. number is 62722.2\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "checker = oovChecker()\n",
    "misspellTokens = checker.misspellIdentify()\n",
    "print('misspellTokens',misspellTokens)\n",
    "candidate = checker.candidateGenerator(misspellTokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD CODE\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline(\"fill-mask\")\n",
    "print(nlp.tokenizer.mask_token)\n",
    "sample2= 'this is my India. My name is Rajat Goel. I use thru. Net income was $9.4 million compared to the prior year of $2.7 <mask>. my number is 5362722.2'\n",
    "print(nlp(sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sequence = 'this is my India. My name is Rajat Goel. It was [MASK]. Net income was $9.4 million compared to the prior year of $2.7 [MASK]. my number is 5362722.2'\n",
    "\n",
    "print('mask',tokenizer.mask_token)\n",
    "\n",
    "input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "print('mask_token_index',mask_token_index)\n",
    "\n",
    "token_logits = model(input)[0]\n",
    "print(token_logits)\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[1].tolist()\n",
    "print('top_5_tokens',torch.topk(mask_token_logits, 5, dim=1))\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print('token', tokenizer.decode([token]))\n",
    "#     print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[17.1059, 14.7497, 11.3313, 10.9787, 10.6195]\n",
    "for i in a:\n",
    "    print(i/sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\"])\n",
    "# nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "\n",
    "doc = nlp(\"this is my pakistan. My name is Rajat Goel. I use tru. Net income was $9.4 million compared to the prior year of $2.7 milion. my number is 5362722.2\")\n",
    "\n",
    "        \n",
    "from spacy.vocab import Vocab\n",
    "with open('./uncased_L-4_H-512_A-8/vocab.txt') as f:\n",
    "    # if want to remove '[unusedXX]' from vocab\n",
    "    # words = [line.rstrip() for line in f if not line.startswith('[unused')]\n",
    "    words = [line.rstrip() for line in f]\n",
    "    \n",
    "vocab = Vocab(strings=words)\n",
    "# for i in tokens:\n",
    "#     print(i.text.lower() in vocab, i.text)\n",
    "\n",
    "\n",
    "# a= [token for token in doc if (token.text.lower() not in vocab  & token.ent_type != 'PERSON') ]\n",
    "\n",
    "lst = []\n",
    "for token in doc:\n",
    "    print(token.text, token.ent_type_)\n",
    "    if((token.text.lower() not in vocab) and (token.ent_type_ != 'PERSON') and (not token.like_num)):\n",
    "#         print(token.text, token.ent_type_, token.is_digit, token.like_num)\n",
    "        lst.append(token)\n",
    "        \n",
    "print(lst)\n",
    "# print(a[0].i,a[0], a[0].ent_type)\n",
    "\n",
    "# print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "print(nlp.entity.labels)\n",
    "print(len(vocab))\n",
    "\"apple\" in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
